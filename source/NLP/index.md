# NLP

## embedding
### word2vec (NIPS 2013)
[Distributed Representations of Words and Phrases and their Compositionality](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)
[Efficient estimation of word representations in vector space](https://arxiv.org/abs/1301.3781)
[google code archive](https://code.google.com/archive/p/word2vec/)


[word2vec Parameter Learning Explained](https://arxiv.org/abs/1411.2738)

[The Illustrated Word2vec](https://jalammar.github.io/illustrated-word2vec/)


## ELMo (NAACL 2018)
[Deep contextualized word representations](https://arxiv.org/abs/1802.05365)  
**E**mbeddings from **L**anguage **Mo**dels  
[code](https://allennlp.org/elmo)  
LSTM

## Transformer (NIPS 2017)
[Attention is all you need](https://arxiv.org/abs/1706.03762)

[The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)

## BERT (2018)
[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
[Google AI Blog: Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)

[\[R\] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://www.reddit.com/r/MachineLearning/comments/9nfqxz/r_bert_pretraining_of_deep_bidirectional/)

[The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](http://jalammar.github.io/illustrated-bert/)




Tasks:
1. Sentence Pair Classification
2. Single Sentence Classification
3. Question Answering
4. Single Sentence Tagging