# GAN Metrics
## Inception Score
proposed by [Improved techniques for training GANs (NIPS 2016)](https://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf), section 4  
apply the Inception model to every generated image to get the conditional label distribution `$p(y|x)$`  
based on 2 assumptions
1. Images that contain meaningful objects should have a conditional label distribution `$p(y|x)$` with low entropy.  
i.e. real photo have higher probably belong to 1 class
1. The model to generate varied images, so the marginal `$\inf p(y|x = G(z)) dz$` should have high entropy.  
i.e. a good generative model should output different classes uniformly  

`$ IS=e^{\mathbb{E}_{x~p_G} D_{KL}(p(y|x)||p(y)} $`
`$ x~p_G $` : sample generated by generator
`$ p(y|x) $`: the conditional label distribution of generated sample x
`$ p(y) $`: average conditional label distribution of all generated samples
`$ D_{KL}(P||Q) $` : [Kullback–Leibler divergence](../math/Kullback-Leibler_divergence.md)
* larger IS -> larger KL-distance -> distribution of single generated sample is different from average -> (based on 2 assumptions) better generator
### Disadvantage
* IS do not use the statistics of real world samples and compare it to the statistics of synthetic samples

## Fréchet Inception Distance (FID)
introduced by [GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium](https://arxiv.org/abs/1706.08500) section A1  
Let `$p(.)$` be distribution of model samples, `$p_w(.)$` be distrubtion of samples from real world, 
The Fréchet distance `$d(., .)$` between the Gaussian with mean and covariance `$(m, \sigma)$` obtained from `$p(.)$` and the Gaussian `$(m_w, \sigma_w)$` obtained from `$p_w(.)$`
`$ d^2{((m,C),{m_w, C_w)} = ||m-m_w||^2_2 + Trace(\sigma+\sigma_w - 2 \sqrt{(\sigma \sigma_w)}) $`
* the lower FID, the better GAN

## Learned Perceptual Image Patch Similarity (LPIPS)
[The Unreasonable Effectiveness of Deep Features as a Perceptual Metric(CVPR 2018)](https://zpascal.net/cvpr2018/Zhang_The_Unreasonable_Effectiveness_CVPR_2018_paper.pdf)
to measure the average feature distances between generated samples. Higher LPIPS scores indicate better diversity among the generated images.
